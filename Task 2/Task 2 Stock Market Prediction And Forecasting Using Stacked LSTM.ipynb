{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f666e8a1",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e04730c1",
   "metadata": {},
   "source": [
    "# LetsGrowMore (LGMVIP- APRIL2022)\n",
    "Sumit Jangir\n",
    "\n",
    "## Task 2 - Stock Market Prediction And Forecasting Using Stacked LSTM\n",
    "\n",
    "### Data = https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv \n",
    "\n",
    "In this model I have used the **Stacked LSTM** (Long Short Term Memory), a Machine Learning Model for Stock Market Prediction. Stock market prediction is the act of trying to determine the future value of a company stock or other financial instrument traded on a financial exchange.\n",
    "\n",
    "![0_dtiuqS8kNB66Mp5P.png](attachment:0_dtiuqS8kNB66Mp5P.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392548bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d78f",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8504ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fbb504",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e94387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check basic info of data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae324598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistical summaries of dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = df.reset_index()['Close']\n",
    "df_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a28955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is there any null values present of not\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e852884",
   "metadata": {},
   "source": [
    "Here we can see no null values present in dataset\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue= 'Turnover (Lacs)', palette= \"rocket\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d84838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = df.reset_index()['Close']\n",
    "df_close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254968c",
   "metadata": {},
   "source": [
    "Let us plot the Close value graph using pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f9a1e",
   "metadata": {},
   "source": [
    "* **Let us plot the Close value graph using pyplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(df_close, c= \"b\")\n",
    "plt.ylabel(\"Close value\")\n",
    "plt.title('Close value graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba038591",
   "metadata": {},
   "source": [
    "* **Let us plot the High value graph using pyplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "df_high=df.reset_index()['High']\n",
    "plt.plot(df_high, c=\"g\")\n",
    "plt.ylabel(\"High value\")\n",
    "plt.title('High value graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072fbce",
   "metadata": {},
   "source": [
    "* **Since LSTM are sensitive to the scale of the data, so we apply MinMax Scaler to transform our values between 0 and 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e0fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "df_high = scaler.fit_transform(np.array(df_high).reshape(-1,1))\n",
    "df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dfac4",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "* In time-series data the one data is dependent on other data. The training size should be 75% of the total length of the data frame, the test size should be the difference between the length of the dataset and the training size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b579b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(df_high) * 0.75)\n",
    "test_size = len(df_high) - training_size\n",
    "train_data, test_data = df_high[0:training_size,:], df_high[training_size:len(df_high),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Data :',train_data.size)\n",
    "print('Training Data :',test_data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639f268",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 100\n",
    "x_train, y_train = create_dataset(train_data, time_step)\n",
    "x_test, y_test = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb3475",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "* Reshape the input to be [samples, time steps, features] which is the requirement of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0905e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378395a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X Training Data :\",x_train.shape)\n",
    "print(\"X testing Data :\",x_test.shape)\n",
    "print(\"Y Training Data :\",y_train.shape)\n",
    "print(\"Y Tresting Data :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd2040",
   "metadata": {},
   "source": [
    "* **Import required modules for the stacked LSTM.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2657fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking my tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c60c03",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences = True, input_shape = (100,1)))\n",
    "model.add(LSTM(50, return_sequences = True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd21266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb38a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 100, batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets predict and check performance metrics\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform back to original form\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fa32d",
   "metadata": {},
   "source": [
    "## Calculating RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523792f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate RMSE performance metrics\n",
    "math.sqrt(mean_squared_error(y_train, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b10b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data RMSE\n",
    "math.sqrt(mean_squared_error(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc5d12",
   "metadata": {},
   "source": [
    "## Plotting the graph according to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "\n",
    "#Shift train prediction for plotting\n",
    "look_back = 100\n",
    "trainPredictPlot = np.empty_like(df_high)\n",
    "trainPredictPlot[:,:] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict) + look_back, :] = train_predict\n",
    "\n",
    "#Shift test prediction for plotting\n",
    "testPredictPlot = np.empty_like(df_high)\n",
    "testPredictPlot[:,:] = np.nan\n",
    "testPredictPlot[len(train_predict) + (look_back * 2)+1:len(df_high) - 1, :] = test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c19aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot baseline and predictions\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(scaler.inverse_transform(df_high))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "print(\"Green indicates the Predicted Data\")\n",
    "print(\"Blue indicates the Complete Data\")\n",
    "print(\"Orange indicates the Train Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the next 28 days Stock Price\n",
    "print(\"Length of Test Data : \",len(test_data))\n",
    "print(\"Shape of x Test Data :\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=test_data[409:].reshape(1,-1)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965863",
   "metadata": {},
   "source": [
    "## Predicting values for next 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = list(x_input)\n",
    "temp_input = temp_input[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433a391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_output=[]\n",
    "n_steps=100\n",
    "i=0\n",
    "while(i<30):\n",
    "    \n",
    "    if(len(temp_input)>100):\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        print(len(temp_input))\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42165b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new = np.arange(1,101)\n",
    "day_pred = np.arange(101,131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(day_new.shape)\n",
    "print(day_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988247b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = df_high.tolist()\n",
    "ds3.extend(lst_output)\n",
    "\n",
    "len(df_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de81419",
   "metadata": {},
   "source": [
    "* **Graph of actual values in last 100 days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "plt.plot(day_new, scaler.inverse_transform(df_high[1935:]))\n",
    "plt.plot(day_pred, scaler.inverse_transform(lst_output))\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('values')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909077d",
   "metadata": {},
   "source": [
    "* **Graph of predicted values for last 65 days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae6640",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "ds3=df_high.tolist()\n",
    "ds3.extend(lst_output)\n",
    "plt.plot(ds3[2000:])\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "ds3=scaler.inverse_transform(ds3).tolist()\n",
    "plt.plot(ds3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f473b57",
   "metadata": {},
   "source": [
    "## Model Created Successfully !\n",
    "# Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
